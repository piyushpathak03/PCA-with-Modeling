# PCA-with-Modeling
# [Principle component Analysis](https://github.com/piyushpathak03/Dimension-Reduction-Techniques/blob/master/PCA.ipynb)
![alt text](https://github.com/piyushpathak03/Dimension-Reduction-Techniques/blob/master/pca.gif)
<br />

Principal Component Analysis, or PCA, is a dimensionality-reduction method that is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information in the large set.

Reducing the number of variables of a data set naturally comes at the expense of accuracy, but the trick in dimensionality reduction is to trade a little accuracy for simplicity. Because smaller data sets are easier to explore and visualize and make analyzing data much easier and faster for machine learning algorithms without extraneous variables to process.

So to sum up, the idea of PCA is simple â€” reduce the number of variables of a data set, while preserving as much information as possible.

![alt text](https://github.com/piyushpathak03/Dimension-Reduction-Techniques/blob/master/PCA1.gif)
<br />

## About me

**Piyush Pathak**

[**PORTFOLIO**](https://anirudhrapathak3.wixsite.com/piyush)

[**GITHUB**](https://github.com/piyushpathak03)

[**BLOG**](https://medium.com/@piyushpathak03)


# ðŸ“« Follw me: 

[![Linkedin Badge](https://img.shields.io/badge/-PiyushPathak-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/piyushpathak03/)](https://www.linkedin.com/in/piyushpathak03/)

<p  align="right"><img height="100" src = "https://media.giphy.com/media/l3URDstnIjBNY7rwLB/giphy.gif"></p>
